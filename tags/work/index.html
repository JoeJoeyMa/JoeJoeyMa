<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="alternate" type="application/rss+xml" title="JoeJoeyMA" href="https://joejoey.tk"><link rel="stylesheet" href="/styles.css"><title>标签：work | JoeJoeyMA</title></head><body><div class="container"><div class="columns page-header"><h1>JoeJoeyMA</h1></div><div class="columns"><div class="navigation"><nav class="menus-main"><a href="/" class="favicon"><img alt="JoeJoeyMA" src="/favicon.png"></a><a href="/">Home</a></nav><nav class="right menus-right"><a href="/atom.xml">RSS</a><a target="_blank" href="hexo-theme-simpleblock">fork on Github</a></nav></div></div><div class="columns"><div class="block-body column three-fourths"><div class="article-widget"><a href="https://github.com/JoeJoeyMa"> </a></div><div class="article-widget"><strong>标签 #work</strong></div><article><header><h2><a href="/2013/09/10/Python小爬虫的那些事/">Python小爬虫的那些事</a></h2></header><div class="article-meta clearfix"><time class="left">2013-09-10</time><ul class="tags left"></ul><ul class="tags right"><li><a href="/tags/Life/">Life</a></li><li><a href="/tags/work/">work</a></li><li><a href="/tags/python/">python</a></li><li><a href="/tags/爬虫/">爬虫</a></li></ul></div><div class="markdown-body"><h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><p>从接触计算机以来，一直都有着想深入了解一门语言。也是因为有做着网络电商的原因吧，店家每天都一直维护干着同样或者是类似流水线式的工作,每天得上传自己的产品修改着宝贝详细里的描述，有时也得观察着同行的一举一动。让我拥有了想做一个真正脚本的想法念头，解放自己的劳动力！<br>俗话说的好解放劳动力才能增大自己的生产里，从琐碎事里摆脱，做着认为对自己有用的事情才能增长。</p>
<p>Python抓取网页方法，任务是批量下载网站上的文件。对于一个刚刚入门python的人来说，在很多细节上都有需要注意的地方，以下就分享一下在初学python过程中遇到的问题及解决方法。<br>学习Python，当然少不了环境的配置，最初我用的是Notepad++，不过发现它的提示功能实在是太弱了，于是，在Windows下我用了PyCharm，在Linux下我用了Eclipse for Python，另外还有几款比较优秀的IDE</p>
<h2 id="urllib库"><a href="#urllib库" class="headerlink" title="urllib库"></a>urllib库</h2><p> Python万能的胶水语言使得让它有更大的活力，以至于在爬虫这个领域中也诞生的很多库。</p>
<pre><code>response = urllib2.urlopen(&quot;http://www.baidu.com&quot;)
urlopen(url, data, timeout)
print response.read()

import urllib2

request = urllib2.Request(&quot;http://www.baidu.com&quot;)
response = urllib2.urlopen(request)
print response.read()
</code></pre><p>那么就开始吧</p>
<pre><code>import urllib
import urllib2
import re
import tool
import os
</code></pre><p>#抓取买家主页个人介绍<br>class Spider:</p>
<pre><code>#页面初始化
def __init__(self):
    self.siteURL = &apos;http://mm.taobao.com/json/request_top_list.htm&apos;
    self.tool = tool.Tool()

#获取索引页面的内容
def getPage(self,pageIndex):
    url = self.siteURL + &quot;?page=&quot; + str(pageIndex)
    request = urllib2.Request(url)
    response = urllib2.urlopen(request)
    return response.read().decode(&apos;gbk&apos;)

#获取索引界面所有MM的信息，list格式
def getContents(self,pageIndex):
    page = self.getPage(pageIndex)
    pattern = re.compile(&apos;&lt;div class=&quot;list-item&quot;.*?pic-word.*?&lt;a href=&quot;(.*?)&quot;.*?&lt;img src=&quot;(.*?)&quot;.*?&lt;a class=&quot;lady-name.*?&gt;(.*?)&lt;/a&gt;.*?&lt;strong&gt;(.*?)&lt;/strong&gt;.*?&lt;span&gt;(.*?)&lt;/span&gt;&apos;,re.S)
    items = re.findall(pattern,page)
    contents = []
    for item in items:
        contents.append([item[0],item[1],item[2],item[3],item[4]])
    return contents

#获取MM个人详情页面
def getDetailPage(self,infoURL):
    response = urllib2.urlopen(infoURL)
    return response.read().decode(&apos;gbk&apos;)

#获取个人文字简介
def getBrief(self,page):
    pattern = re.compile(&apos;&lt;div class=&quot;mm-aixiu-content&quot;.*?&gt;(.*?)&lt;!--&apos;,re.S)
    result = re.search(pattern,page)
    return self.tool.replace(result.group(1))

#获取页面所有图片
def getAllImg(self,page):
    pattern = re.compile(&apos;&lt;div class=&quot;mm-aixiu-content&quot;.*?&gt;(.*?)&lt;!--&apos;,re.S)
    #个人信息页面所有代码
    content = re.search(pattern,page)
    #从代码中提取图片
    patternImg = re.compile(&apos;&lt;img.*?src=&quot;(.*?)&quot;&apos;,re.S)
    images = re.findall(patternImg,content.group(1))
    return images


#保存多张图片
def saveImgs(self,images,name):
    number = 1
    print u&quot;发现&quot;,name,u&quot;共有&quot;,len(images),u&quot;张照片&quot;
    for imageURL in images:
        splitPath = imageURL.split(&apos;.&apos;)
        fTail = splitPath.pop()
        if len(fTail) &gt; 3:
            fTail = &quot;jpg&quot;
        fileName = name + &quot;/&quot; + str(number) + &quot;.&quot; + fTail
        self.saveImg(imageURL,fileName)
        number += 1

# 保存头像
def saveIcon(self,iconURL,name):
    splitPath = iconURL.split(&apos;.&apos;)
    fTail = splitPath.pop()
    fileName = name + &quot;/icon.&quot; + fTail
    self.saveImg(iconURL,fileName)

#保存个人简介
def saveBrief(self,content,name):
    fileName = name + &quot;/&quot; + name + &quot;.txt&quot;
    f = open(fileName,&quot;w+&quot;)
    print u&quot;正在偷偷保存她的个人信息为&quot;,fileName
    f.write(content.encode(&apos;utf-8&apos;))


#传入图片地址，文件名，保存单张图片
def saveImg(self,imageURL,fileName):
     u = urllib.urlopen(imageURL)
     data = u.read()
     f = open(fileName, &apos;wb&apos;)
     f.write(data)
     print u&quot;正在悄悄保存她的一张图片为&quot;,fileName
     f.close()

#创建新目录
def mkdir(self,path):
    path = path.strip()
    # 判断路径是否存在
    # 存在     True
    # 不存在   False
    isExists=os.path.exists(path)
    # 判断结果
    if not isExists:
        # 如果不存在则创建目录
        print u&quot;偷偷新建了名字叫做&quot;,path,u&apos;的文件夹&apos;
        # 创建目录操作函数
        os.makedirs(path)
        return True
    else:
        # 如果目录存在则不创建，并提示目录已存在
        print u&quot;名为&quot;,path,&apos;的文件夹已经创建成功&apos;
        return False

#将一页淘宝MM的信息保存起来
def savePageInfo(self,pageIndex):
    #获取第一页淘宝列表
    contents = self.getContents(pageIndex)
    for item in contents:
        #item[0]个人详情URL,item[1]头像URL,item[2]姓名,item[3]年龄,item[4]居住地
        print u&quot;发现一位,名字叫&quot;,item[2],u&quot;age&quot;,item[3],u&quot;,在&quot;,item[4]
        print u&quot;正在保存&quot;,item[2],&quot;的信息&quot;
        print u&quot;个人地址是&quot;,item[0]
        #个人详情页面的URL
        detailURL = item[0]
        #得到个人详情页面代码
        detailPage = self.getDetailPage(detailURL)
        #获取个人简介
        brief = self.getBrief(detailPage)
        #获取所有图片列表
        images = self.getAllImg(detailPage)
        self.mkdir(item[2])
        #保存个人简介
        self.saveBrief(brief,item[2])
        #保存头像
        self.saveIcon(item[1],item[2])
        #保存图片
        self.saveImgs(images,item[2])

#传入起止页码，获取图片
def savePagesInfo(self,start,end):
    for i in range(start,end+1):
        print u&quot;正在找第&quot;,i,u&quot;个地方，看看在不在&quot;
        self.savePageInfo(i)
</code></pre><p>#传入起止页码即可，在此传入了2,10,表示抓取第2到10页<br>spider = Spider()<br>spider.savePagesInfo(2,10)</p>
<h2 id="Request库"><a href="#Request库" class="headerlink" title="Request库"></a>Request库</h2><p>使用 Requests 发送网络请求非常简单。</p>
<pre><code>import requests
</code></pre><p>requests库提供了http所有的基本请求方式</p>
<pre><code>r = requests.post(&quot;http://httpbin.org/post&quot;)
r = requests.put(&quot;http://httpbin.org/put&quot;)
r = requests.delete(&quot;http://httpbin.org/delete&quot;)
r = requests.head(&quot;http://httpbin.org/get&quot;)
r = requests.options(&quot;http://httpbin.org/get&quot;)
</code></pre><p>一次完整的请求</p>
<pre><code>import requests
r = requests.get(&apos;https://taobao.com&apos;)
r.text
</code></pre><h2 id="Scripts"><a href="#Scripts" class="headerlink" title="Scripts"></a>Scripts</h2></div></article><article><header><h2><a href="/2013/07/13/电子商务/">电子商务</a></h2></header><div class="article-meta clearfix"><time class="left">2013-07-13</time><ul class="tags left"></ul><ul class="tags right"><li><a href="/tags/Life/">Life</a></li><li><a href="/tags/work/">work</a></li></ul></div><div class="markdown-body"><h2 id="电子商务？"><a href="#电子商务？" class="headerlink" title="电子商务？"></a>电子商务？</h2><p>过去的时间里发生了很多事，其中最大的变化应该是家庭缘故吧，作为在广州出生长大的潮汕人，从小家里就做着各种生意。父亲也时常教育着我们要学习好英语才能和外国人做外贸，在未来帮我们铺垫了道路—-商务英语国际外贸专业。<br>也是珠三角地带的特点，让每个家庭都运营着前店后厂的形式。每个做生意的人都存在的各种大大小小形式的库存。恰好马云这几年来的宣传，使得电子商贸流行起来了</p>
<p>电子商务的本质是什么?许多人的认知都会不一样，我认为电子商务是技术驱动的交易便利化。电商的本质依然是零售，只是将线下的交易搬到了线上。虽然本质没变，但它带来的便利性、高效是革命性的 </p>
<h2 id="开网店"><a href="#开网店" class="headerlink" title="开网店"></a>开网店</h2><p>在家人的凑合下，便开启了做网店的道路,自己的小店还是门可罗雀,自己在淘宝购物也有几百了，但是没想到成为卖家，出售商品是困难。自己是很认真的在经营自己的小店，才刚刚开始，家里人也鼓励我，刚开始都是这样的。我也在不断坚定自己的信心，好怕哪天信心都磨光了。慢慢的由于自己也是相当与厂家直销，价格也比其他人低廉，销量也稳步慢慢上涨着，看在每天都忙得不可开交，一个人又要打包也得当小二客服和顾客沟通，处理日常，运营着店铺大大小小的事情，有时还得不得不赔偿退款。虽然也没什么利润，但过的也充实着</p>
</div></article><div class="archive-pagination"><div class="paginator"><span class="page-number current">1</span></div></div></div><div class="block-sidebar column one-fourth"><div class="widget text-content"><p>Simple Block 是一个基于线框设计的简单的 Hexo
支持使用 Jade 或 Markdown 来向边栏添加小部件，或向正文前添加横幅。</p>
<p>技术栈：</p>
<ul>
<li>Jade - 页面模板</li>
<li>Less/Sass - 页面样式</li>
<li>Bower - 前端包管理器</li>
<li>CoffeeScript - Hexo 拓展脚本</li>
<li>Gulp - 编译工具</li>
</ul>
</div><div class="widget tags"><ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Life/">Life</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/work/">work</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/初中/">初中</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul></div><div class="widget archives"><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/09/">September 2013</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/07/">July 2013</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2011/11/">November 2011</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2011/09/">September 2011</a><span class="archive-list-count">1</span></li></ul></div><div class="widget text-content"><p>该博客使用基于 &nbsp;<a href="http://hexo.io">Hexo</a>&nbsp; 的 &nbsp;<a href="https://github.com/jysperm/hexo-theme-simpleblock">simpleblock</a>&nbsp; 主题。博客内容使用 &nbsp;<a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn">CC BY-NC-SA 3.0</a>&nbsp; 授权发布。最后生成于 2018-02-13.</p></div></div></div></div></body></html>